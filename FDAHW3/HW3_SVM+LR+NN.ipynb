{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理及引入函式庫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 將作業指定的trainset 與testset併入同組pd.series，以方便計算。\n",
    "#### 2.所欲預測lable需定義明確，一開始我將今日收盤價減去昨日收盤價，若大於0則得到1，是漲，相反則是跌；這麼做是想預測股票漲跌，但其實沒有意義，因為機器已經看過今日與昨日收盤價，所以預測準確率會很高(將近八成)。 因此重新定義明確的label，是\"預測隔日漲跌\"，將今日收盤價減去隔日收盤價，這樣預測才有意義。\n",
    "#### 3.切分特徵群與標記群，並丟棄日期特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    1372\n",
      "0.0    1143\n",
      "Name: Value, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomshiue\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:47: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by the scale function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>daydiffirence</th>\n",
       "      <th>dayopenchange</th>\n",
       "      <th>openchange</th>\n",
       "      <th>volumechangepercent</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>17.10</td>\n",
       "      <td>26.18</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>0.252246515</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>16.57</td>\n",
       "      <td>2</td>\n",
       "      <td>3.72</td>\n",
       "      <td>-0.003947985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>25.08</td>\n",
       "      <td>-3.72</td>\n",
       "      <td>-7.25</td>\n",
       "      <td>-0.146161268</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>13.19</td>\n",
       "      <td>-21.72</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.057419023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "      <td>23.62</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.058316545</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price  High Price  Low Price      Volume  daydiffirence  \\\n",
       "1      929.17       927.45      936.63     919.53  5413910016          17.10   \n",
       "2      931.17       934.70      943.85     927.28  5392620032          16.57   \n",
       "3      927.45       906.65      927.45     902.37  4704940032          25.08   \n",
       "4      905.73       909.73      910.00     896.81  4991549952          13.19   \n",
       "5      909.91       890.35      911.93     888.31  4716499968          23.62   \n",
       "\n",
       "  dayopenchange openchange volumechangepercent  Value  \n",
       "1         26.18      -2.63         0.252246515    1.0  \n",
       "2             2       3.72        -0.003947985    0.0  \n",
       "3         -3.72      -7.25        -0.146161268    1.0  \n",
       "4        -21.72      -0.92         0.057419023    0.0  \n",
       "5          4.18       0.18        -0.058316545    0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note: change range no influence\n",
    "#note:change attributes has some influence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics, model_selection,preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm,preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "\n",
    " \n",
    "file_name = 'stocktrain.csv'\n",
    "train = pd.read_csv(file_name)\n",
    "\n",
    "file_name2 = 'stocktest.csv'\n",
    "test = pd.read_csv(file_name2)\n",
    "#總共2516筆資料，為操作方便，將test併入train，並記得後252筆為TEST DATA\n",
    "data=pd.concat([train,test])\n",
    "#data=data.loc[0:2515,:]\n",
    "\n",
    "value = pd.Series(data['Close Price']-data['Close Price'].shift(1),\\\n",
    "                  index=data.index)\n",
    "value = value.bfill()\n",
    "value[value>=0]=1 \n",
    "value[value<0]=0 \n",
    "data['Value']=value.shift(-1)\n",
    "#\"Value\"表示隔天漲跌、漲為1\n",
    "\n",
    "result = pd.value_counts(data['Value'])\n",
    "print(result)\n",
    "\n",
    "data=data.drop(['Date'],axis=1)\n",
    "data=data.drop(0,axis=0)\n",
    "#因為有與昨日價差，故第一筆資料會有null 故刪除\n",
    "\n",
    "#data=data.drop(['Close Price'],axis=1)\n",
    "#data=data.drop(['Open Price'],axis=1)\n",
    "#data=data.drop(['High Price'],axis=1)\n",
    "#data=data.drop(['Low Price'],axis=1)\n",
    "#data=data.drop(['Volume'],axis=1)\n",
    "\n",
    "\n",
    "x_data = data.loc[:, data.columns != 'Value']\n",
    "x_data=preprocessing.scale(x_data)\n",
    "y_data = data.loc[:,'Value']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.在SVM中，一開始只將原始資料的全部特徵丟進去訓練，但發覺速度非常慢而且全部值都猜一，可以說是沒訓練好(準確率就是1的比率，大約52%)，後來多新增了四個特徵，是關於價格差以及成交量差，大幅提高訓練速度，且也有真的在預測的行為，不是全猜一，可能是因為SVM演算法的關係，若都只有單純價格會造成演算困難。\n",
    "#### 2. 採用演算模型方面，則是poly的表現最好，故以下皆是用poly討論。\n",
    "#### 3.測試不同penalty，C=3時 Train 與test的平均表現較好 ，C>3發生overfitting情況。故選擇 test accuracy=54.365% 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1\n",
      "Train Accuracy = 55.639% \n",
      "Test Accuracy=53.968%\n",
      "C=2\n",
      "Train Accuracy = 55.816% \n",
      "Test Accuracy=52.778%\n",
      "C=3\n",
      "Train Accuracy = 55.772% \n",
      "Test Accuracy=54.365%\n",
      "C=4\n",
      "Train Accuracy = 55.860% \n",
      "Test Accuracy=53.175%\n",
      "C=5\n",
      "Train Accuracy = 55.949% \n",
      "Test Accuracy=52.381%\n",
      "Wall time: 3.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for C in range(1,6):\n",
    "    print(\"C=%d\"%C)\n",
    "    L=len(x_data)-1\n",
    "    train_i=int(L*(2263/2515))\n",
    "    \n",
    "#固定訓練集->模型固定，並預測後252天，也就是2018年的每天漲跌\n",
    "    correct = 0\n",
    "    train_original=train_i\n",
    "    total_predict_data=L-train_i\n",
    "\n",
    "    Data_train=x_data[0:int((2263/2515)*L)]\n",
    "    value_train = y_data[0:int((2263/2515)*L)]\n",
    "\n",
    "\n",
    "    classifier = svm.SVC(C, kernel='poly',gamma='auto') \n",
    "    classifier.fit(Data_train,value_train)\n",
    "\n",
    "    acct_rate = accuracy_score(value_train, classifier.predict(Data_train))\n",
    "    train_accuracy=acct_rate*100\n",
    "    print(\"Train Accuracy = %.3f%% \" %  train_accuracy)\n",
    "\n",
    "    while train_i<L:\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        Data_predict=x_data[train_i:train_i+1]\n",
    "        value_real = y_data[train_i:train_i+1]\n",
    " \n",
    "    \n",
    "        value_predict=classifier.predict(Data_predict)\n",
    "    \n",
    "    #print(\"predictdata_index=%d  value_real=%d value_predict=%d\"%(train_i,value_real,value_predict))\n",
    "    \n",
    "    #若預測正確，則correct計數器+1\n",
    "        if(int(value_real)==int(value_predict)):\n",
    "            correct=correct+1\n",
    "        train_i = train_i+1\n",
    "\n",
    "#印出準確度\n",
    "    correct=correct*100/total_predict_data\n",
    "    print(\"Test Accuracy=%.3f%%\"%correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.採用同樣方式前處理後的資料， test accuracy=53.571% ，略低於SVM。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 54.931% \n",
      "Test Accuracy=53.571%\n",
      "Wall time: 67.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "L=len(x_data)-1\n",
    "train_i=int(L*(2263/2515))\n",
    "\n",
    "\n",
    "#固定訓練集->模型固定，並預測後252天，也就是2018年的每天漲跌\n",
    "correct = 0\n",
    "train_original=train_i\n",
    "total_predict_data=L-train_i\n",
    "\n",
    "Data_train=x_data[0:int((2263/2515)*L)]\n",
    "value_train = y_data[0:int((2263/2515)*L)]\n",
    "\n",
    "\n",
    "classifier = LogisticRegression(solver='lbfgs').fit(Data_train, value_train)\n",
    "\n",
    "\n",
    "acct_rate = accuracy_score(value_train, classifier.predict(Data_train))\n",
    "train_accuracy=acct_rate*100\n",
    "print(\"Train Accuracy = %.3f%% \" %  train_accuracy)\n",
    "\n",
    "while train_i<L:\n",
    "    \n",
    "    \n",
    "    \n",
    "    Data_predict=x_data[train_i:train_i+1]\n",
    "    value_real = y_data[train_i:train_i+1]\n",
    " \n",
    "    \n",
    "    value_predict=classifier.predict(Data_predict)\n",
    "    \n",
    "    #print(\"predictdata_index=%d  value_real=%d value_predict=%d\"%(train_i,value_real,value_predict))\n",
    "    \n",
    "    #若預測正確，則correct計數器+1\n",
    "    if(int(value_real)==int(value_predict)):\n",
    "        correct=correct+1\n",
    "    train_i = train_i+1\n",
    "\n",
    "#印出準確度\n",
    "correct=correct*100/total_predict_data\n",
    "print(\"Test Accuracy=%.3f%%\"%correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 使用同一筆前處理的資料，NN模型每個預測值都猜一，所以準確度就是1的比率 ，test accuracy =52.381% 。\n",
    "#### 2. 已經調整了所有可調的參數，卻仍舊無法成功訓練，應是對NN還不夠熟悉，可能是activation function或其他原因。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 1000   # how many neurons in the hidden layer\n",
    "activation = 'relu'  # activation function for hidden layer\n",
    "l2 = 0.0001          # regularization - how much we penalize large parameter values\n",
    "learning_rate = 1e-3  # how big our steps are in gradient descent\n",
    "epochs = 20          # how many epochs to train for\n",
    "batch_size = 64     # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\tomshiue\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=9,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation,\n",
    "                       kernel_regularizer=regularizers.l2(l2)))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1, \n",
    "                       activation='softmax',\n",
    "                       kernel_regularizer=regularizers.l2(l2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {\n",
    "    0: 1.,\n",
    "    1: 1144/1372\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\tomshiue\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "2261/2261 [==============================] - 0s 142us/step - loss: 7.2073\n",
      "Epoch 2/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2064\n",
      "Epoch 3/20\n",
      "2261/2261 [==============================] - 0s 16us/step - loss: 7.2062\n",
      "Epoch 4/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 5/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 6/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 7/20\n",
      "2261/2261 [==============================] - 0s 16us/step - loss: 7.2062\n",
      "Epoch 8/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 9/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 10/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 11/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 12/20\n",
      "2261/2261 [==============================] - 0s 15us/step - loss: 7.2062\n",
      "Epoch 13/20\n",
      "2261/2261 [==============================] - 0s 16us/step - loss: 7.2062\n",
      "Epoch 14/20\n",
      "2261/2261 [==============================] - 0s 14us/step - loss: 7.2062\n",
      "Epoch 15/20\n",
      "2261/2261 [==============================] - 0s 14us/step - loss: 7.2062\n",
      "Epoch 16/20\n",
      "2261/2261 [==============================] - 0s 17us/step - loss: 7.2062\n",
      "Epoch 17/20\n",
      "2261/2261 [==============================] - 0s 17us/step - loss: 7.2062\n",
      "Epoch 18/20\n",
      "2261/2261 [==============================] - 0s 17us/step - loss: 7.2062\n",
      "Epoch 19/20\n",
      "2261/2261 [==============================] - 0s 16us/step - loss: 7.2062\n",
      "Epoch 20/20\n",
      "2261/2261 [==============================] - 0s 18us/step - loss: 7.2062\n",
      "Train Accuracy = 54.799% \n",
      "predictdata_index=2261  value_real=0 value_predict=1\n",
      "predictdata_index=2262  value_real=1 value_predict=1\n",
      "predictdata_index=2263  value_real=1 value_predict=1\n",
      "predictdata_index=2264  value_real=1 value_predict=1\n",
      "predictdata_index=2265  value_real=1 value_predict=1\n",
      "predictdata_index=2266  value_real=1 value_predict=1\n",
      "predictdata_index=2267  value_real=0 value_predict=1\n",
      "predictdata_index=2268  value_real=1 value_predict=1\n",
      "predictdata_index=2269  value_real=1 value_predict=1\n",
      "predictdata_index=2270  value_real=0 value_predict=1\n",
      "predictdata_index=2271  value_real=1 value_predict=1\n",
      "predictdata_index=2272  value_real=0 value_predict=1\n",
      "predictdata_index=2273  value_real=1 value_predict=1\n",
      "predictdata_index=2274  value_real=1 value_predict=1\n",
      "predictdata_index=2275  value_real=1 value_predict=1\n",
      "predictdata_index=2276  value_real=0 value_predict=1\n",
      "predictdata_index=2277  value_real=1 value_predict=1\n",
      "predictdata_index=2278  value_real=1 value_predict=1\n",
      "predictdata_index=2279  value_real=0 value_predict=1\n",
      "predictdata_index=2280  value_real=0 value_predict=1\n",
      "predictdata_index=2281  value_real=1 value_predict=1\n",
      "predictdata_index=2282  value_real=0 value_predict=1\n",
      "predictdata_index=2283  value_real=0 value_predict=1\n",
      "predictdata_index=2284  value_real=0 value_predict=1\n",
      "predictdata_index=2285  value_real=1 value_predict=1\n",
      "predictdata_index=2286  value_real=0 value_predict=1\n",
      "predictdata_index=2287  value_real=0 value_predict=1\n",
      "predictdata_index=2288  value_real=1 value_predict=1\n",
      "predictdata_index=2289  value_real=1 value_predict=1\n",
      "predictdata_index=2290  value_real=1 value_predict=1\n",
      "predictdata_index=2291  value_real=1 value_predict=1\n",
      "predictdata_index=2292  value_real=1 value_predict=1\n",
      "predictdata_index=2293  value_real=1 value_predict=1\n",
      "predictdata_index=2294  value_real=0 value_predict=1\n",
      "predictdata_index=2295  value_real=0 value_predict=1\n",
      "predictdata_index=2296  value_real=1 value_predict=1\n",
      "predictdata_index=2297  value_real=1 value_predict=1\n",
      "predictdata_index=2298  value_real=1 value_predict=1\n",
      "predictdata_index=2299  value_real=0 value_predict=1\n",
      "predictdata_index=2300  value_real=0 value_predict=1\n",
      "predictdata_index=2301  value_real=0 value_predict=1\n",
      "predictdata_index=2302  value_real=1 value_predict=1\n",
      "predictdata_index=2303  value_real=1 value_predict=1\n",
      "predictdata_index=2304  value_real=1 value_predict=1\n",
      "predictdata_index=2305  value_real=0 value_predict=1\n",
      "predictdata_index=2306  value_real=1 value_predict=1\n",
      "predictdata_index=2307  value_real=1 value_predict=1\n",
      "predictdata_index=2308  value_real=0 value_predict=1\n",
      "predictdata_index=2309  value_real=0 value_predict=1\n",
      "predictdata_index=2310  value_real=0 value_predict=1\n",
      "predictdata_index=2311  value_real=0 value_predict=1\n",
      "predictdata_index=2312  value_real=1 value_predict=1\n",
      "predictdata_index=2313  value_real=0 value_predict=1\n",
      "predictdata_index=2314  value_real=1 value_predict=1\n",
      "predictdata_index=2315  value_real=0 value_predict=1\n",
      "predictdata_index=2316  value_real=0 value_predict=1\n",
      "predictdata_index=2317  value_real=0 value_predict=1\n",
      "predictdata_index=2318  value_real=1 value_predict=1\n",
      "predictdata_index=2319  value_real=0 value_predict=1\n",
      "predictdata_index=2320  value_real=0 value_predict=1\n",
      "predictdata_index=2321  value_real=1 value_predict=1\n",
      "predictdata_index=2322  value_real=0 value_predict=1\n",
      "predictdata_index=2323  value_real=1 value_predict=1\n",
      "predictdata_index=2324  value_real=1 value_predict=1\n",
      "predictdata_index=2325  value_real=1 value_predict=1\n",
      "predictdata_index=2326  value_real=0 value_predict=1\n",
      "predictdata_index=2327  value_real=1 value_predict=1\n",
      "predictdata_index=2328  value_real=1 value_predict=1\n",
      "predictdata_index=2329  value_real=0 value_predict=1\n",
      "predictdata_index=2330  value_real=1 value_predict=1\n",
      "predictdata_index=2331  value_real=0 value_predict=1\n",
      "predictdata_index=2332  value_real=1 value_predict=1\n",
      "predictdata_index=2333  value_real=1 value_predict=1\n",
      "predictdata_index=2334  value_real=1 value_predict=1\n",
      "predictdata_index=2335  value_real=0 value_predict=1\n",
      "predictdata_index=2336  value_real=0 value_predict=1\n",
      "predictdata_index=2337  value_real=1 value_predict=1\n",
      "predictdata_index=2338  value_real=0 value_predict=1\n",
      "predictdata_index=2339  value_real=1 value_predict=1\n",
      "predictdata_index=2340  value_real=1 value_predict=1\n",
      "predictdata_index=2341  value_real=1 value_predict=1\n",
      "predictdata_index=2342  value_real=0 value_predict=1\n",
      "predictdata_index=2343  value_real=1 value_predict=1\n",
      "predictdata_index=2344  value_real=0 value_predict=1\n",
      "predictdata_index=2345  value_real=0 value_predict=1\n",
      "predictdata_index=2346  value_real=1 value_predict=1\n",
      "predictdata_index=2347  value_real=1 value_predict=1\n",
      "predictdata_index=2348  value_real=0 value_predict=1\n",
      "predictdata_index=2349  value_real=1 value_predict=1\n",
      "predictdata_index=2350  value_real=1 value_predict=1\n",
      "predictdata_index=2351  value_real=1 value_predict=1\n",
      "predictdata_index=2352  value_real=1 value_predict=1\n",
      "predictdata_index=2353  value_real=0 value_predict=1\n",
      "predictdata_index=2354  value_real=1 value_predict=1\n",
      "predictdata_index=2355  value_real=0 value_predict=1\n",
      "predictdata_index=2356  value_real=0 value_predict=1\n",
      "predictdata_index=2357  value_real=1 value_predict=1\n",
      "predictdata_index=2358  value_real=0 value_predict=1\n",
      "predictdata_index=2359  value_real=1 value_predict=1\n",
      "predictdata_index=2360  value_real=0 value_predict=1\n",
      "predictdata_index=2361  value_real=0 value_predict=1\n",
      "predictdata_index=2362  value_real=0 value_predict=1\n",
      "predictdata_index=2363  value_real=1 value_predict=1\n",
      "predictdata_index=2364  value_real=0 value_predict=1\n",
      "predictdata_index=2365  value_real=1 value_predict=1\n",
      "predictdata_index=2366  value_real=1 value_predict=1\n",
      "predictdata_index=2367  value_real=1 value_predict=1\n",
      "predictdata_index=2368  value_real=1 value_predict=1\n",
      "predictdata_index=2369  value_real=0 value_predict=1\n",
      "predictdata_index=2370  value_real=1 value_predict=1\n",
      "predictdata_index=2371  value_real=1 value_predict=1\n",
      "predictdata_index=2372  value_real=1 value_predict=1\n",
      "predictdata_index=2373  value_real=0 value_predict=1\n",
      "predictdata_index=2374  value_real=1 value_predict=1\n",
      "predictdata_index=2375  value_real=0 value_predict=1\n",
      "predictdata_index=2376  value_real=0 value_predict=1\n",
      "predictdata_index=2377  value_real=0 value_predict=1\n",
      "predictdata_index=2378  value_real=1 value_predict=1\n",
      "predictdata_index=2379  value_real=0 value_predict=1\n",
      "predictdata_index=2380  value_real=1 value_predict=1\n",
      "predictdata_index=2381  value_real=0 value_predict=1\n",
      "predictdata_index=2382  value_real=1 value_predict=1\n",
      "predictdata_index=2383  value_real=0 value_predict=1\n",
      "predictdata_index=2384  value_real=1 value_predict=1\n",
      "predictdata_index=2385  value_real=1 value_predict=1\n",
      "predictdata_index=2386  value_real=1 value_predict=1\n",
      "predictdata_index=2387  value_real=0 value_predict=1\n",
      "predictdata_index=2388  value_real=1 value_predict=1\n",
      "predictdata_index=2389  value_real=1 value_predict=1\n",
      "predictdata_index=2390  value_real=1 value_predict=1\n",
      "predictdata_index=2391  value_real=1 value_predict=1\n",
      "predictdata_index=2392  value_real=0 value_predict=1\n",
      "predictdata_index=2393  value_real=1 value_predict=1\n",
      "predictdata_index=2394  value_real=1 value_predict=1\n",
      "predictdata_index=2395  value_real=0 value_predict=1\n",
      "predictdata_index=2396  value_real=1 value_predict=1\n",
      "predictdata_index=2397  value_real=1 value_predict=1\n",
      "predictdata_index=2398  value_real=0 value_predict=1\n",
      "predictdata_index=2399  value_real=0 value_predict=1\n",
      "predictdata_index=2400  value_real=1 value_predict=1\n",
      "predictdata_index=2401  value_real=1 value_predict=1\n",
      "predictdata_index=2402  value_real=1 value_predict=1\n",
      "predictdata_index=2403  value_real=0 value_predict=1\n",
      "predictdata_index=2404  value_real=0 value_predict=1\n",
      "predictdata_index=2405  value_real=0 value_predict=1\n",
      "predictdata_index=2406  value_real=1 value_predict=1\n",
      "predictdata_index=2407  value_real=0 value_predict=1\n",
      "predictdata_index=2408  value_real=1 value_predict=1\n",
      "predictdata_index=2409  value_real=1 value_predict=1\n",
      "predictdata_index=2410  value_real=1 value_predict=1\n",
      "predictdata_index=2411  value_real=1 value_predict=1\n",
      "predictdata_index=2412  value_real=0 value_predict=1\n",
      "predictdata_index=2413  value_real=0 value_predict=1\n",
      "predictdata_index=2414  value_real=0 value_predict=1\n",
      "predictdata_index=2415  value_real=0 value_predict=1\n",
      "predictdata_index=2416  value_real=1 value_predict=1\n",
      "predictdata_index=2417  value_real=0 value_predict=1\n",
      "predictdata_index=2418  value_real=1 value_predict=1\n",
      "predictdata_index=2419  value_real=1 value_predict=1\n",
      "predictdata_index=2420  value_real=1 value_predict=1\n",
      "predictdata_index=2421  value_real=1 value_predict=1\n",
      "predictdata_index=2422  value_real=0 value_predict=1\n",
      "predictdata_index=2423  value_real=0 value_predict=1\n",
      "predictdata_index=2424  value_real=1 value_predict=1\n",
      "predictdata_index=2425  value_real=1 value_predict=1\n",
      "predictdata_index=2426  value_real=1 value_predict=1\n",
      "predictdata_index=2427  value_real=1 value_predict=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictdata_index=2428  value_real=0 value_predict=1\n",
      "predictdata_index=2429  value_real=1 value_predict=1\n",
      "predictdata_index=2430  value_real=0 value_predict=1\n",
      "predictdata_index=2431  value_real=0 value_predict=1\n",
      "predictdata_index=2432  value_real=0 value_predict=1\n",
      "predictdata_index=2433  value_real=0 value_predict=1\n",
      "predictdata_index=2434  value_real=1 value_predict=1\n",
      "predictdata_index=2435  value_real=1 value_predict=1\n",
      "predictdata_index=2436  value_real=1 value_predict=1\n",
      "predictdata_index=2437  value_real=1 value_predict=1\n",
      "predictdata_index=2438  value_real=1 value_predict=1\n",
      "predictdata_index=2439  value_real=0 value_predict=1\n",
      "predictdata_index=2440  value_real=1 value_predict=1\n",
      "predictdata_index=2441  value_real=1 value_predict=1\n",
      "predictdata_index=2442  value_real=1 value_predict=1\n",
      "predictdata_index=2443  value_real=0 value_predict=1\n",
      "predictdata_index=2444  value_real=0 value_predict=1\n",
      "predictdata_index=2445  value_real=0 value_predict=1\n",
      "predictdata_index=2446  value_real=0 value_predict=1\n",
      "predictdata_index=2447  value_real=1 value_predict=1\n",
      "predictdata_index=2448  value_real=0 value_predict=1\n",
      "predictdata_index=2449  value_real=1 value_predict=1\n",
      "predictdata_index=2450  value_real=0 value_predict=1\n",
      "predictdata_index=2451  value_real=1 value_predict=1\n",
      "predictdata_index=2452  value_real=0 value_predict=1\n",
      "predictdata_index=2453  value_real=0 value_predict=1\n",
      "predictdata_index=2454  value_real=0 value_predict=1\n",
      "predictdata_index=2455  value_real=0 value_predict=1\n",
      "predictdata_index=2456  value_real=0 value_predict=1\n",
      "predictdata_index=2457  value_real=0 value_predict=1\n",
      "predictdata_index=2458  value_real=1 value_predict=1\n",
      "predictdata_index=2459  value_real=0 value_predict=1\n",
      "predictdata_index=2460  value_real=1 value_predict=1\n",
      "predictdata_index=2461  value_real=0 value_predict=1\n",
      "predictdata_index=2462  value_real=0 value_predict=1\n",
      "predictdata_index=2463  value_real=0 value_predict=1\n",
      "predictdata_index=2464  value_real=0 value_predict=1\n",
      "predictdata_index=2465  value_real=0 value_predict=1\n",
      "predictdata_index=2466  value_real=0 value_predict=1\n",
      "predictdata_index=2467  value_real=1 value_predict=1\n",
      "predictdata_index=2468  value_real=0 value_predict=1\n",
      "predictdata_index=2469  value_real=0 value_predict=1\n",
      "predictdata_index=2470  value_real=1 value_predict=1\n",
      "predictdata_index=2471  value_real=1 value_predict=1\n",
      "predictdata_index=2472  value_real=1 value_predict=1\n",
      "predictdata_index=2473  value_real=0 value_predict=1\n",
      "predictdata_index=2474  value_real=1 value_predict=1\n",
      "predictdata_index=2475  value_real=1 value_predict=1\n",
      "predictdata_index=2476  value_real=1 value_predict=1\n",
      "predictdata_index=2477  value_real=0 value_predict=1\n",
      "predictdata_index=2478  value_real=0 value_predict=1\n",
      "predictdata_index=2479  value_real=0 value_predict=1\n",
      "predictdata_index=2480  value_real=0 value_predict=1\n",
      "predictdata_index=2481  value_real=0 value_predict=1\n",
      "predictdata_index=2482  value_real=1 value_predict=1\n",
      "predictdata_index=2483  value_real=1 value_predict=1\n",
      "predictdata_index=2484  value_real=0 value_predict=1\n",
      "predictdata_index=2485  value_real=0 value_predict=1\n",
      "predictdata_index=2486  value_real=1 value_predict=1\n",
      "predictdata_index=2487  value_real=0 value_predict=1\n",
      "predictdata_index=2488  value_real=1 value_predict=1\n",
      "predictdata_index=2489  value_real=1 value_predict=1\n",
      "predictdata_index=2490  value_real=1 value_predict=1\n",
      "predictdata_index=2491  value_real=0 value_predict=1\n",
      "predictdata_index=2492  value_real=1 value_predict=1\n",
      "predictdata_index=2493  value_real=1 value_predict=1\n",
      "predictdata_index=2494  value_real=0 value_predict=1\n",
      "predictdata_index=2495  value_real=1 value_predict=1\n",
      "predictdata_index=2496  value_real=0 value_predict=1\n",
      "predictdata_index=2497  value_real=0 value_predict=1\n",
      "predictdata_index=2498  value_real=1 value_predict=1\n",
      "predictdata_index=2499  value_real=0 value_predict=1\n",
      "predictdata_index=2500  value_real=1 value_predict=1\n",
      "predictdata_index=2501  value_real=0 value_predict=1\n",
      "predictdata_index=2502  value_real=0 value_predict=1\n",
      "predictdata_index=2503  value_real=0 value_predict=1\n",
      "predictdata_index=2504  value_real=1 value_predict=1\n",
      "predictdata_index=2505  value_real=0 value_predict=1\n",
      "predictdata_index=2506  value_real=0 value_predict=1\n",
      "predictdata_index=2507  value_real=0 value_predict=1\n",
      "predictdata_index=2508  value_real=0 value_predict=1\n",
      "predictdata_index=2509  value_real=1 value_predict=1\n",
      "predictdata_index=2510  value_real=1 value_predict=1\n",
      "predictdata_index=2511  value_real=0 value_predict=1\n",
      "predictdata_index=2512  value_real=1 value_predict=1\n",
      "Test Accuracy=52.381%\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "L=len(x_data)-1\n",
    "train_i=int(L*(2263/2515))\n",
    "\n",
    "\n",
    "#固定訓練集->模型固定，並預測後252天，也就是2018年的每天漲跌\n",
    "correct = 0\n",
    "train_original=train_i\n",
    "total_predict_data=L-train_i\n",
    "\n",
    "Data_train=x_data[0:int((2263/2515)*L)]\n",
    "value_train = y_data[0:int((2263/2515)*L)]\n",
    "\n",
    "\n",
    "history= model.fit(Data_train, value_train, epochs=20, batch_size=batch_size,class_weight=class_weight)\n",
    "\n",
    "\n",
    "acct_rate = accuracy_score(value_train, model.predict(Data_train))\n",
    "train_accuracy=acct_rate*100\n",
    "print(\"Train Accuracy = %.3f%% \" %  train_accuracy)\n",
    "\n",
    "\n",
    "while train_i<L:\n",
    "    \n",
    "    Data_train=x_data[train_i-train_original:train_i]\n",
    "    value_train = y_data[train_i-train_original:train_i]\n",
    "    \n",
    "    Data_predict=x_data[train_i:train_i+1]\n",
    "    value_real = y_data[train_i:train_i+1]\n",
    " \n",
    "     \n",
    "    \n",
    "    value_predict=model.predict(Data_predict)\n",
    "    \n",
    "    #print(\"predictdata_index=%d  value_real=%d value_predict=%d\"%(train_i,value_real,value_predict))\n",
    "    \n",
    "    #若預測正確，則correct計數器+1\n",
    "    if(int(value_real)==int(value_predict)):\n",
    "        correct=correct+1\n",
    "    train_i = train_i+1\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#印出準確度\n",
    "correct=correct*100/total_predict_data\n",
    "print(\"Test Accuracy=%.3f%%\"%correct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Summary\n",
    "#### 從這次作業練習到了三個分類器，SVM是能較為精確且穩定的分類，LR則是較快速但粗略，NN應該是最複雜但也能最精準的，很可能沒有訓練好NN。  也從這次作業知道 ， 資料好壞的重要，可能造成garbage in garbage out，所以在訓練模型前，要好好思考所要的lable及需要的attributes是什麼，並做好適當的前處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
